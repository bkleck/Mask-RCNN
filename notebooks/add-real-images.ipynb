{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2\n",
    "from shapely.geometry import Polygon\n",
    "import itertools\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract json data and transform into required COCO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4032 3024\n"
     ]
    }
   ],
   "source": [
    "# first we get the image size\n",
    "# since all taken in iPhone, we just need to check 1 image\n",
    "im = cv2.imread('data/listerine_real/IMG_0181.jpg')\n",
    "h, w, c = im.shape\n",
    "print(h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we are using listerine, we set the category ID\n",
    "cat_id = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from the json file\n",
    "with open('data/listerine_real/listerine_json.json') as f:\n",
    "    d = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open train and mask json\n",
    "with open('data/listerine#23-11-21#05 20 PM/61be142d-ca8c-4e0e-95b9-752494d232d4/train/images/annotations.json') as f:\n",
    "    train = json.load(f)\n",
    "    \n",
    "with open('data/listerine#23-11-21#05 20 PM/61be142d-ca8c-4e0e-95b9-752494d232d4/val/images/annotations.json') as f:\n",
    "    val = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we start image & mask ID from 1000 to avoid overlap with synthetic data\n",
    "image_count = 1000\n",
    "mask_count = 1000\n",
    "\n",
    "# store the images we filtered into both train and val datasets\n",
    "train_imgs = []\n",
    "val_imgs = []\n",
    "\n",
    "for key in d.keys():\n",
    "    # this is the dictionary to append to images list\n",
    "    dict_1 = {\n",
    "            \"file_name\": d[key]['filename'],\n",
    "            \"height\": h,\n",
    "            \"width\": w,\n",
    "            \"id\": image_count \n",
    "            }\n",
    "    \n",
    "    # this logic is used to split real image dataset equally into train n val\n",
    "    if image_count < 1015:\n",
    "        train['images'].append(dict_1)\n",
    "        train_imgs.append(d[key]['filename'])\n",
    "    else:\n",
    "        val['images'].append(dict_1)\n",
    "        val_imgs.append(d[key]['filename'])\n",
    "\n",
    "        \n",
    "    for segment in d[key]['regions']:\n",
    "        x = segment['shape_attributes']['all_points_x']\n",
    "        y = segment['shape_attributes']['all_points_y']\n",
    "        \n",
    "        # get the area of the polygon from the points\n",
    "        pgon = Polygon(zip(x, y))\n",
    "        area = pgon.area\n",
    "        \n",
    "        # combine the x and y coordinates into 1 alternating list\n",
    "        coords = [i for i in itertools.chain.from_iterable(itertools.zip_longest(x,y)) if i]\n",
    "        \n",
    "        # get bbox coordinates\n",
    "        bbox = [min(x), min(y), max(x), max(y)]\n",
    "        \n",
    "        # this is the dictionary to append to annotations list\n",
    "        dict_2 = {\n",
    "                \"segmentation\": [ coords ],\n",
    "                \"area\": area,\n",
    "                \"iscrowd\": 0,\n",
    "                \"image_id\": image_count,\n",
    "                \"bbox\": bbox,\n",
    "                \"category_id\": cat_id,\n",
    "                \"id\": mask_count\n",
    "                }\n",
    "        \n",
    "        # this logic is used to split real image dataset equally into train n val\n",
    "        if image_count < 1015:\n",
    "            train['annotations'].append(dict_2)\n",
    "        else:\n",
    "            train['annotations'].append(dict_2)\n",
    "        \n",
    "        mask_count += 1\n",
    "        \n",
    "    image_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save new info back to train and mask json\n",
    "with open('data/listerine#23-11-21#05 20 PM/61be142d-ca8c-4e0e-95b9-752494d232d4/train/images/annotations.json', 'w') as f:\n",
    "    json.dump(train, f)\n",
    "    \n",
    "with open('data/listerine#23-11-21#05 20 PM/61be142d-ca8c-4e0e-95b9-752494d232d4/val/images/annotations.json', 'w') as f:\n",
    "    json.dump(val, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy images into their respective folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in train_imgs:\n",
    "    file_path = 'data/listerine_real/' + file\n",
    "    shutil.copy(file_path, 'data/listerine#23-11-21#05 20 PM/61be142d-ca8c-4e0e-95b9-752494d232d4/train/images/')\n",
    "\n",
    "for file in val_imgs:\n",
    "    file_path = 'data/listerine_real/' + file\n",
    "    shutil.copy(file_path, 'data/listerine#23-11-21#05 20 PM/61be142d-ca8c-4e0e-95b9-752494d232d4/val/images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
